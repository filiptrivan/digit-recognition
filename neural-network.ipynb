{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55bb9b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d5c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = utils.get_train_data()\n",
    "X = np.array(training_data.drop(columns=['label']))\n",
    "y = np.array(training_data['label'])\n",
    "X_test = np.array(utils.get_test_data())\n",
    "y_test = np.array(utils.get_test_labels()).ravel()\n",
    "training_data = list(zip(X, y))\n",
    "test_data = list(zip(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ed995e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight matrix 0 shape: (784, 15)\n",
      "Weight matrix 1 shape: (15, 15)\n",
      "Weight matrix 2 shape: (15, 10)\n",
      "Bias vector 0 shape: (1, 15)\n",
      "Bias vector 1 shape: (1, 15)\n",
      "Bias vector 2 shape: (1, 10)\n",
      "(1, 10)\n",
      "(1, 15)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1,10) and (15,1) not aligned: 10 (dim 1) != 15 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBias vector \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# utils.draw_neural_net(neuron.layer_sizes, max_neurons=20)\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m network\u001b[38;5;241m.\u001b[39mforward(X)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(network\u001b[38;5;241m.\u001b[39mactivations[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\user\\Documents\\Projects\\TestProjects\\digit-recognition\\utils.py:141\u001b[0m, in \u001b[0;36mNeuralNetwork.SGD\u001b[1;34m(self, training_data, epochs, mini_batch_size, alpha, test_data)\u001b[0m\n\u001b[0;32m    137\u001b[0m mini_batches \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    138\u001b[0m     training_data[k:k\u001b[38;5;241m+\u001b[39mmini_batch_size]\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, n, mini_batch_size)]\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mini_batch \u001b[38;5;129;01min\u001b[39;00m mini_batches:\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_mini_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmini_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_data:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(j, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(test_data), n_test))\n",
      "File \u001b[1;32mc:\\Users\\user\\Documents\\Projects\\TestProjects\\digit-recognition\\utils.py:156\u001b[0m, in \u001b[0;36mNeuralNetwork.update_mini_batch\u001b[1;34m(self, mini_batch, alpha)\u001b[0m\n\u001b[0;32m    152\u001b[0m weights_temp \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mzeros(w\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights]\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m mini_batch:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# FT: Backprop is a fast way for calculating gradients of weights and biases\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Calculates how much each weight should change for x, y pair\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m     delta_weights_temp, delta_biases_temp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackprop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     weights_temp \u001b[38;5;241m=\u001b[39m [nw \u001b[38;5;241m+\u001b[39m dnw \n\u001b[0;32m    158\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m nw, dnw \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(weights_temp, delta_weights_temp)]\n\u001b[0;32m    159\u001b[0m     biases_temp \u001b[38;5;241m=\u001b[39m [nb \u001b[38;5;241m+\u001b[39m dnb \n\u001b[0;32m    160\u001b[0m                    \u001b[38;5;28;01mfor\u001b[39;00m nb, dnb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(biases_temp, delta_biases_temp)]\n",
      "File \u001b[1;32mc:\\Users\\user\\Documents\\Projects\\TestProjects\\digit-recognition\\utils.py:187\u001b[0m, in \u001b[0;36mNeuralNetwork.backprop\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28mprint\u001b[39m(delta\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28mprint\u001b[39m(activations[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 187\u001b[0m weights_temp[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m biases_temp[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m delta\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# Note that the variable l in the loop below is used a little\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# differently to the notation in Chapter 2 of the book.  Here,\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# l = 1 means the last layer of neurons, l = 2 is the\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# second-last layer, and so on.  It's a renumbering of the\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# scheme in the book, used here to take advantage of the fact\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# that Python can use negative indices in lists.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1,10) and (15,1) not aligned: 10 (dim 1) != 15 (dim 0)"
     ]
    }
   ],
   "source": [
    "network = utils.NeuralNetwork([784, 15, 15, 10])\n",
    "\n",
    "for i, w in enumerate(network.weights):\n",
    "    print(f\"Weight matrix {i} shape: {w.shape}\")\n",
    "\n",
    "for i, b in enumerate(network.biases):\n",
    "    print(f\"Bias vector {i} shape: {b.shape}\")\n",
    "\n",
    "# utils.draw_neural_net(neuron.layer_sizes, max_neurons=20)\n",
    "\n",
    "network.SGD(training_data, 30, 10, 0.1)\n",
    "network.forward(X)\n",
    "print(network.activations[-1])\n",
    "# W, B, cost_history = utils.train_neural_network(X, y, alpha=0.00001, lambd=0.5, epochs=100, num_classes=10)\n",
    "\n",
    "# utils.plot_cost(cost_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
